{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All needed imports\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Camera Calibration\n",
    "The camera calibration is done with the help of serveral images of the same chessboard using the same camera taken\n",
    "from different angels. The next two methods extract the image and object points from the given imagaes and calculate the cameramatrix and distoration matrix for the given camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Camera Calibration\n",
    "def extract_image_and_object_points(image_dir, chessboard_x=9, chessboard_y=6):\n",
    "    \"\"\"\n",
    "    Extracts the image points and onbject points from the given image_dir\n",
    "\n",
    "    Args:\n",
    "        image_dir:    The path glob which can be used to find the images\n",
    "        chessboard_x: The chessboard corners in the x axis\n",
    "        chessboard_y: The chessboard corners in the y axis\n",
    "\n",
    "    Returns:\n",
    "        The pickle file that conatin both of these data.\n",
    "    \"\"\"\n",
    "    objp = np.zeros((chessboard_x * chessboard_y, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:chessboard_x, 0:chessboard_y].T.reshape(-1, 2)\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    images = glob.glob(image_dir)\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(\n",
    "            gray, (chessboard_x, chessboard_y), None)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    return imgpoints, objpoints\n",
    "\n",
    "\n",
    "def get_image_and_distortion_matrix(image_dir,\n",
    "                                    test_image,\n",
    "                                    chessboard_x=9,\n",
    "                                    chessboard_y=6):\n",
    "    \"\"\"\n",
    "    Returns the image matrix and ditortion matrix for the given image, image points and object points\n",
    "\n",
    "    Args:\n",
    "        image_dir:    The path glob which can be used to find the images\n",
    "        test_image:   The array like image or PIL image\n",
    "        chessboard_x: The chessboard corners in the x axis\n",
    "        chessboard_y: The chessboard corners in the y axis\n",
    "\n",
    "    Returns:\n",
    "        The pickel file that contains the distorations\n",
    "    \"\"\"\n",
    "    imgpoints, objpoints = extract_image_and_object_points(image_dir)\n",
    "    img_size = (test_image.shape[1], test_image.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,\n",
    "                                                       img_size, None, None)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    dist_pickle['imgpoints'] = imgpoints\n",
    "    dist_pickle['objpoints'] = objpoints\n",
    "    pickle.dump(dist_pickle, open(\"calibrate_dist_pickle.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"camera_cal/calibration14.jpg\")\n",
    "get_image_and_distortion_matrix('camera_cal/*.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Undistort\n",
    "Having caclulated the camera and distortion matrix, every image created by the same camrea can be distorted and transformed. This is done by the next command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply the calibration to remove distoration on the given raw images\n",
    "def undistort_and_transform(img,\n",
    "                            chessboard_x=9,\n",
    "                            chessboard_y=6,\n",
    "                            calibrate_pickle='calibrate_dist_pickle.p'):\n",
    "    \"\"\"\n",
    "    Undistort the given image with the help of calibrate pickel created before.\n",
    "\n",
    "    Args:\n",
    "        img: The array like image or PIL image\n",
    "        calibrate_pickle: The path to the pickle file that should contain the image matrix and distorations\n",
    "\n",
    "    Returns:\n",
    "        Returns the undistorted image.\n",
    "    \"\"\"\n",
    "    dist_pickle = pickle.load(open(calibrate_pickle, \"rb\"))\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    grayscale = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(\n",
    "        undist, (chessboard_x, chessboard_y), None)\n",
    "    M = None\n",
    "    warped = np.copy(undist)\n",
    "    if ret == True:\n",
    "        cv2.drawChessboardCorners(undist, (chessboard_x, chessboard_y),\n",
    "                                  corners, ret)\n",
    "        image_size = undist.shape[1::-1]\n",
    "        src_points = np.float32([\n",
    "            corners[0], corners[chessboard_x - 1], corners[-1],\n",
    "            corners[-chessboard_x]\n",
    "        ])\n",
    "        offset = 50\n",
    "        dst_points = np.float32(\n",
    "            [[offset, offset], [image_size[0] - offset, offset],\n",
    "             [image_size[0] - offset, image_size[1] - offset],\n",
    "             [offset, image_size[1] - offset]])\n",
    "        M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "        warped = cv2.warpPerspective(\n",
    "            undist, M, image_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M\n",
    "\n",
    "def undistort_image(img, calibrate_pickle='calibrate_dist_pickle.p'):\n",
    "    \"\"\"\n",
    "    Undistorts the given image with the calibration pickel\n",
    "    \n",
    "    Args:\n",
    "        img: The image that should be used is the array like image or PIL\n",
    "        calibrate_pickle: The pickle file that should be used for the source of calibration\n",
    "        \n",
    "    Returns:\n",
    "        The undistorted image\n",
    "    \"\"\"\n",
    "    dist_pickle = pickle.load(open(calibrate_pickle, \"rb\"))\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"camera_cal/calibration1.jpg\")\n",
    "top_down, perspective_M = undistort_and_transform(img)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = cv2.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    top_down = undistort_image(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(output_dir + \"undistorted_\" + image_name, top_down)\n",
    "    top_down = cv2.cvtColor(top_down, cv2.COLOR_BGR2RGB)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original-' + image_name, fontsize=25)\n",
    "    ax2.imshow(top_down)\n",
    "    ax2.set_title('Undistorted - ' + image_name, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Create Threshold binary image\n",
    "To create a threshold binary image the following steps should be taken:\n",
    "\n",
    "- Undisort the image\n",
    "- Use the HLS color space (Mainly the S) to limit the colors in the image\n",
    "- Use Sobel gradient in direction and magnitude\n",
    "- Combine the gradient and limited color image togehther and with this create the binary image\n",
    "\n",
    "Results of this operation can be found in the `output_image/binary_*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_select_s(img, thresh=(0, 255)):\n",
    "    \"\"\"\n",
    "    Applies the HLS threshold on the given image.\n",
    "    \n",
    "    Args:\n",
    "        img: The image that should be used\n",
    "        thresh: The threshold for the given image\n",
    "        \n",
    "    Returns:\n",
    "        img\n",
    "    \"\"\"\n",
    "    img_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = img_hls[:, :, 2]\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def sobel_process(img, orient='x', thresh_min=20, thresh_max=100):\n",
    "    \"\"\"\n",
    "    Adds the sobel process to the given image.\n",
    "    \n",
    "    Args:\n",
    "        img: The image like array\n",
    "        oreint: The Sobel orientation, could be x or y\n",
    "        thresh_min: The minimum threshold for the sobel\n",
    "        thresh_max: The maximum threshold for the sobel\n",
    "        \n",
    "    Return:\n",
    "        image like array that is processed.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = cv2.normalize(abs_sobel, None, 0.0, 255.0, cv2.NORM_MINMAX,\n",
    "                                 cv2.CV_64F)\n",
    "    sxbinary = cv2.inRange(scaled_sobel, thresh_min, thresh_max)\n",
    "    retval, sxbinary = cv2.threshold(sxbinary, 250, 1.0, cv2.THRESH_BINARY)\n",
    "    return sxbinary\n",
    "\n",
    "\n",
    "def direction_threshold(img, sobel_kernel=3, thresh=(0, np.pi / 2)):\n",
    "    \"\"\"\n",
    "    Creates the direction threshold with the help of Sobel\n",
    "    \n",
    "    Args:\n",
    "        img: The image that should be manipulated\n",
    "        sobel_kernel: The size of the sobel kernel\n",
    "        thresh: The threshold value for the direction threshold\n",
    "    \n",
    "    Returns:\n",
    "        img\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    sobel_dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    sbinary = cv2.inRange(sobel_dir, thresh[0], thresh[1])\n",
    "    retval, sbinary = cv2.threshold(sbinary, thresh[1] - 0.1, 1.0,\n",
    "                                    cv2.THRESH_BINARY)\n",
    "    return sbinary\n",
    "\n",
    "\n",
    "def magnitude_threshold(img, sobel_kernel=3, mag_threshold=(0, 255)):\n",
    "    \"\"\"\n",
    "    Creates the magnitude threshold with the help of Sobel\n",
    "    \n",
    "    Args:\n",
    "        img: The image that should be manipulated\n",
    "        sobel_kernel: The size of the sobel kernel\n",
    "        mag_threshold: The threshold magniuted\n",
    "    \n",
    "    Returns:\n",
    "        img\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    mag_sobel = np.sqrt(abs_sobelx**2 + abs_sobely**2)\n",
    "    scaled_sobel = cv2.normalize(mag_sobel, None, 0.0, 255.0, cv2.NORM_MINMAX,\n",
    "                                 cv2.CV_64F)\n",
    "    sbinary = cv2.inRange(scaled_sobel, mag_threshold[0], mag_threshold[1])\n",
    "    retval, sbinary = cv2.threshold(sbinary, 250, 1.0, cv2.THRESH_BINARY)\n",
    "    return sbinary\n",
    "\n",
    "\n",
    "def combined_threshold(image,\n",
    "                       sobel_kernel=15,\n",
    "                       dir_thresh=(0.0, np.pi / 2),\n",
    "                       mag_threshold=(0, 255)):\n",
    "    \"\"\"\n",
    "    Creates the combined threshold for the replacement of the canny detection algorithm\n",
    "    \n",
    "    Args:\n",
    "        image: The array like image that should be used.\n",
    "        sobel_kernel: The size of the sobel kernel\n",
    "        dir_thresh: The threshold that should be used for the sobel function\n",
    "        mag_threshold: The theshold for the magnitude and normal sobel process\n",
    "        \n",
    "    Returns:\n",
    "        image\n",
    "    \"\"\"\n",
    "    gradx = sobel_process(image, 'x', mag_threshold[0], mag_threshold[1])\n",
    "    grady = sobel_process(image, 'y', mag_threshold[0], mag_threshold[1])\n",
    "    mag_binary = magnitude_threshold(image, sobel_kernel, mag_threshold)\n",
    "    dir_binary = direction_threshold(image, sobel_kernel, dir_thresh)\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) &\n",
    "                                              (dir_binary == 1))] = 1\n",
    "    return combined\n",
    "\n",
    "\n",
    "def get_binary_image(image,\n",
    "                     mag_thresh=(0, 255),\n",
    "                     hls_thresh=(0, 255)):\n",
    "    \"\"\"\n",
    "    Creates the binary image from the given image with help of Sobel and HLS colour space\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        image: The image like array or the PIL image\n",
    "        mag_thresh: The threshold that should be used for the soble magnitude\n",
    "        hls_thresh: The threshold that should be used for the hls colour limiting\n",
    "    \n",
    "    Returns:\n",
    "        The filtered binary image\n",
    "    \"\"\"\n",
    "    hsl_image = hls_select_s(image, hls_thresh)\n",
    "    threshold_image = sobel_process(image, 'x', mag_thresh[0], mag_thresh[1])\n",
    "    combined_binary = np.zeros_like(threshold_image)\n",
    "    combined_binary[(hsl_image == 1) | (threshold_image == 1)] = 1\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = mpimg.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    img = undistort_image(img)\n",
    "    top_down = get_binary_image(img, (20,100),(170,255))\n",
    "    cv2.imwrite(output_dir + \"binary_\" + image_name, top_down * 255)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original - ' + image_name, fontsize=25)\n",
    "    ax2.imshow(top_down, cmap='Greys_r')\n",
    "    ax2.set_title('Binary - ' + image_name, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Perspective transform\n",
    "Using a transform matrix, the binary image will be perspective transformed to a bird-eye view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bird_eye(img, offset = 50):\n",
    "    \"\"\"\n",
    "    Transform the ROI (Region of Interest) of the given image to bird eye\n",
    "    \n",
    "    Args:\n",
    "        img: The array like image or PIL image\n",
    "        offset: The offset for the transformation\n",
    "        \n",
    "    Return:\n",
    "            The transformed image\n",
    "            The transform matrix\n",
    "            The inverse of transform matrix\n",
    "    \"\"\"\n",
    "    imshape = img.shape\n",
    "    img_size = (imshape[1], imshape[0])\n",
    "    left_point =  (1.5 * imshape[1]/8, imshape[0]- 50)\n",
    "    source_apex1 = (imshape[1]/2 - 50 , imshape[0]/2 + 85 )\n",
    "    source_apex2 = (imshape[1]/2 + 50, imshape[0]/2 + 85 )\n",
    "    right_point = (6.5 * imshape[1]/8, imshape[0]- 50)\n",
    "    source = np.float32([[left_point, source_apex1, source_apex2, right_point]])\n",
    "    dest_left_point =  (1.5 * imshape[1]/8  + offset, imshape[0])\n",
    "    dest_apex1 = (1.5 * imshape[1]/8 + offset, 0)\n",
    "    dest_apex2 = (6.5 * imshape[1]/8 - offset, 0)\n",
    "    dest_right_point = (6.5 * imshape[1]/8 - offset, imshape[0])\n",
    "    dest = np.float32([[dest_left_point, dest_apex1, dest_apex2, dest_right_point]])\n",
    "    M = cv2.getPerspectiveTransform(source, dest)\n",
    "    Minv = cv2.getPerspectiveTransform(dest, source)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = mpimg.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    img = undistort_image(img)\n",
    "    top_down, M, Minv = transform_bird_eye(img)\n",
    "    top_down_print = cv2.cvtColor(top_down, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(output_dir + \"bird_eye_\" + image_name, top_down_print)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original - ' + image_name, fontsize=25)\n",
    "    ax2.imshow(top_down)\n",
    "    ax2.set_title('Bird Eye - ' + image_name, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = mpimg.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    img = undistort_image(img)\n",
    "    top_down = get_binary_image(img, (20,100),(170,255))\n",
    "    top_down, M, Minv= transform_bird_eye(top_down)\n",
    "    cv2.imwrite(output_dir + \"bird_eye_binary_\" + image_name, top_down * 255)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original - ' + image_name, fontsize=25)\n",
    "    ax2.imshow(top_down,  cmap='Greys_r')\n",
    "    ax2.set_title('Bird Eye - ' + image_name, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Find the lane pixels\n",
    "After preproccesing the image, it will be fitted to the lane pixel finder, it uses the following steps:\n",
    "\n",
    "- Create a historgram of the images, bottom part so the left and right expected area of the line are found\n",
    "- Use this and the sliding window approach to find the whole line.\n",
    "- Draw it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    \"\"\"\n",
    "    Finds the lane pixels in a binary warped image\n",
    "    \n",
    "    Args:\n",
    "        binary_warped: The binary warped array_like image that should be used to find line\n",
    "        \n",
    "    Returns:\n",
    "        The arrays containing points for the left and right image\n",
    "    \"\"\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0] // 2:, :], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0] // 2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0] // nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low),\n",
    "                      (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low),\n",
    "                      (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                          (nonzerox >= win_xleft_low) &\n",
    "                          (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                           (nonzerox >= win_xright_low) &\n",
    "                           (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped, draw_poly = True):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "    try:\n",
    "        left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0] * ploty**2 + right_fit[\n",
    "            1] * ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1 * ploty**2 + 1 * ploty\n",
    "        right_fitx = 1 * ploty**2 + 1 * ploty\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    if draw_poly is True:\n",
    "        left_points = np.array(list(zip(left_fitx, ploty)),  np.int32)\n",
    "        right_points = np.array(list(zip(right_fitx, ploty)),  np.int32)\n",
    "        cv2.polylines(out_img, [left_points], False, (255,255,0),2)\n",
    "        cv2.polylines(out_img, [right_points], False, (255,255,0), 2)\n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = mpimg.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    img = undistort_image(img)\n",
    "    top_down = get_binary_image(img, (20, 150), (150, 255))\n",
    "    top_down, M, Minv = transform_bird_eye(top_down)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty, out_img = fit_polynomial(top_down)\n",
    "    to_print = cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(output_dir + \"lane_found_\" + image_name, to_print)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original - ' + image_name, fontsize=25)\n",
    "    ax2.imshow(out_img)\n",
    "    ax2.set_title('Pixel Lane - ' + image_name, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Determine the curvature of the lane and vehicle position with respect to center.\n",
    "The curvature of the line is calculate with the given formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(leftx, rightx, ploty, ym_per_pix, xm_per_pix):\n",
    "    '''\n",
    "    Generates fake data to use for calculating lane curvature.\n",
    "    In your own project, you'll ignore this function and instead\n",
    "    feed in the output of your lane detection algorithm to\n",
    "    the lane curvature calculation.\n",
    "    '''\n",
    "    dest = abs(leftx[-1] - rightx[-1])*xm_per_pix\n",
    "    center_of_image = abs(xm_per_pix * 660)\n",
    "    dest_from_center = abs(dest - center_of_image)\n",
    "    left_fit_cr  = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix , 2)\n",
    "    right_fit_cr = np.polyfit(ploty* ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    return ploty, left_fit_cr, right_fit_cr, dest_from_center\n",
    "\n",
    "def measure_curvature_real(left_fit, right_fit, ploty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    \n",
    "    Args:\n",
    "        left_fit: The line that is fitted to the left lane\n",
    "        right_fit: The line that is fitted tot the right lane\n",
    "        ploty: The ploty image.\n",
    "        \n",
    "    Returns:\n",
    "        left_curverad, right_curverad\n",
    "    '''\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    ploty, left_fit_cr, right_fit_cr, dest_from_center = generate_data(left_fit, right_fit, ploty, ym_per_pix, xm_per_pix)\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1])**2)** (3/2))/ np.absolute((2 * left_fit_cr[0]))\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix  + right_fit_cr[1])**2)** (3/2))/ np.absolute((2 * right_fit_cr[0]))\n",
    "    return left_curverad, right_curverad, dest_from_center\n",
    "\n",
    "def sanitize_curvature(left_curverad, right_curverad, max_curvature = 20000):\n",
    "    \"\"\"\n",
    "    Sanitizes the Curvature for the given fit.\n",
    "    \n",
    "    Args:\n",
    "        left_curverad: The left lane curvature in m\n",
    "        right_curverad: The right lane curvature in m\n",
    "        max_curvature: The maximum curvature\n",
    "        \n",
    "    Returns:\n",
    "        The value of the curvature in m\n",
    "    \"\"\"\n",
    "    curvature = (left_curverad + right_curverad)/2\n",
    "    if curvature > max_curvature:\n",
    "        return max_curvature\n",
    "    if curvature > 1000:\n",
    "        return (curvature / 100) * 100\n",
    "    else:\n",
    "        return (curvature / 50) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = mpimg.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    img = undistort_image(img)\n",
    "    top_down = get_binary_image(img, (20, 150), (150, 255))\n",
    "    top_down, M, Minv= transform_bird_eye(top_down)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty, out_img = fit_polynomial(top_down)\n",
    "    left_curverad, right_curverad, dest_from_center =  measure_curvature_real(left_fitx, right_fitx, ploty)\n",
    "    print(\"Curvature: \", image_name, left_curverad, right_curverad)\n",
    "    print(\"Dest:\", dest_from_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Warp the detected lane boundaries back onto the original image.\n",
    "With the help of the transformation matrix used before, the detected lanelines are added to the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_boundires(img, sobel_thresh = (20, 150), hls_thresh=(150, 255)):\n",
    "    \"\"\"\n",
    "    Draw lane boundries on the image\n",
    "    \n",
    "    Args:\n",
    "        img: The img array\n",
    "        sobel_thresh: The sobel threshold\n",
    "        hls_thresh: The threshold for the hls image filter\n",
    "        \n",
    "    Return:\n",
    "        img\n",
    "    \"\"\"\n",
    "    undist = undistort_image(img)\n",
    "    top_down = get_binary_image(undist, sobel_thresh, hls_thresh)\n",
    "    warped, M, Minv = transform_bird_eye(top_down)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty, out_img = fit_polynomial(warped)\n",
    "    left_curverad, right_curverad, dest_from_center =  measure_curvature_real(left_fitx, right_fitx, ploty)\n",
    "    curvature = sanitize_curvature(left_curverad, right_curverad)\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    curvature_text = \"Curvature:% 6.0fm\" % curvature\n",
    "    position_text = \"Position: % 5.2fm\" % dest_from_center\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result, curvature_text,(100,70), font, 2,(0,0,0),2)\n",
    "    cv2.putText(result, position_text, (150,120), font, 2,(0,0,0),2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"test_images/*.jpg\"\n",
    "output_dir = \"output_images/\"\n",
    "images = glob.glob(test_image_dir)\n",
    "for path in images:\n",
    "    img = mpimg.imread(path)\n",
    "    image_name = os.path.basename(path)\n",
    "    top_down = draw_lane_boundires(img, (20, 150), (150, 255))\n",
    "    cv2.imwrite(output_dir + \"lane_drawn_\" + image_name, top_down)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original - ' + image_name, fontsize=25)\n",
    "    ax2.imshow(top_down)\n",
    "    ax2.set_title('Pixel Lane - ' + image_name, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our image - this should be a new frame since last time!\n",
    "binary_warped = mpimg.imread('warped-example.jpg')\n",
    "\n",
    "# Polynomial fit values from the previous frame\n",
    "# Make sure to grab the actual values from the previous step in your project!\n",
    "left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "     ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_poly, right_poly, left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "result = search_around_poly(binary_warped)\n",
    "\n",
    "# View your output\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line(object):\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line for the left lane\n",
    "        self.recent_xfitted_left = deque(maxlen = 10)\n",
    "        # x values of the last n fits of the line for the right lane\n",
    "        self.recent_xfitted_right = deque(maxlen =10)\n",
    "        # average x values of the fitted line over the last n iterations for the left lane\n",
    "        self.best_x_left = None\n",
    "        # average x values of the fitted line over the last n iteration for the right lane\n",
    "        self.best_x_right = None\n",
    "        # polynomial coefficients averaged over the last n iterations for the left lane\n",
    "        self.best_fit_left = None \n",
    "        # polynomial coefficients averaged over the last n iterations for the right lane\n",
    "        self.best_fit_right = None\n",
    "        # polynomial coefficients for the last n fits for the left lane\n",
    "        self.recent_fits_left = deque(maxlen =10)\n",
    "        # polynomial coefficients for the last n fits for the right lane\n",
    "        self.recent_fits_right = deque(maxlen =10)\n",
    "        # polynomial coefficients for the most recent fit for the left lane\n",
    "        self.current_fit_left = [np.array([False])] \n",
    "        # polynomial coeficients for the most recent fir for the right lane\n",
    "        self.current_fit_right = [np.array([False])]\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits for the left lane\n",
    "        self.diffs_left = np.array([0,0,0], dtype='float')\n",
    "        #difference in fit coefficients between last and new fits for the right lane\n",
    "        self.diffs_right = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels for left lane\n",
    "        self.allx_left = None \n",
    "        #x values for detected line pixels for left right\n",
    "        self.allx_right = None\n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "    def get_default_frame_data(self):\n",
    "        \"\"\"\n",
    "        Returns the default frame_data for the given time ine the line\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            frame_data: The FrameData object that should be used.\n",
    "        \"\"\"\n",
    "        frame_data = FrameData()\n",
    "        frame_data.left_fit = self.best_fit_left\n",
    "        frame_data.right_fit = self.best_fit_right\n",
    "        frame_data.left_fitx = self.best_x_left\n",
    "        frame_data.right_fitx = self.best_x_right\n",
    "        frame_data.ploty = ploty\n",
    "        frame_data.curvature = self.radius_of_curvature\n",
    "        frame_data.dest_from_center = self.line_base_pos\n",
    "        return frame_data\n",
    "\n",
    "class FrameData(object):\n",
    "    \"\"\"\n",
    "    The data that is extracted form the given frame.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.left_fit = None\n",
    "        self.left_fitx = None \n",
    "        self.right_fit = None \n",
    "        self.right_fitx = None\n",
    "        self.ploty = None \n",
    "        self.curvature = None\n",
    "        self.right_curverad = None\n",
    "        self.left_curverad = None\n",
    "        self.dest_from_center = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ACCEPTABLE_WIDTH = 1.0 # in meters\n",
    "MAX_ACCEPTABLE_PARALEL = 5.0 # in percent\n",
    "MAX_ACCEPTABLE_LINE_MOVED = .2 # in meters\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "     ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty\n",
    "\n",
    "\n",
    "def brute_force_fit(img, sobel_thresh = (20, 150), hls_thresh=(150, 255)):\n",
    "    \"\"\"\n",
    "    This is the brute force fit that is used only when the normal look a head fitting does not work.\n",
    "    \n",
    "    Args:\n",
    "        img:          The array like image or PIL image\n",
    "        sobel_thresh: The size of the sobel threshold\n",
    "        hls_thresh:   The threshold for the hls binary\n",
    "        \n",
    "    Returns:\n",
    "        frame_data: The frame data which contains all the frame related data.\n",
    "        M:          The Matrix used to the transform the image to bird_eye view\n",
    "        Minv:       The inverse of the matrix that is used to transform images to bird_eye view\n",
    "    \"\"\"\n",
    "    img = undistort_image(img)\n",
    "    top_down = get_binary_image(img, sobel_thresh, hls_thresh)\n",
    "    top_down, M, Minv = transform_bird_eye(top_down)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty, out_img = fit_polynomial(top_down)\n",
    "    left_curverad, right_curverad, dest_from_center =  measure_curvature_real(left_fitx, right_fitx, ploty)\n",
    "    frame_data = FrameData()\n",
    "    frame_data.left_fit = left_fit\n",
    "    frame_data.right_fit = right_fit\n",
    "    frame_data.left_fitx = left_fitx\n",
    "    frame_data.right_fitx = right_fitx\n",
    "    frame_data.ploty = ploty\n",
    "    frame_data.right_curverad = right_curverad\n",
    "    frame_data.left_curverad = left_curverad\n",
    "    frame_data.curvature = sanitize_curvature(left_curverad, right_curverad)\n",
    "    frame_data.dest_from_center = dest_from_center\n",
    "    return frame_data, M, Minv\n",
    "\n",
    "def simple_fit(img, line,  sobel_thresh= (20, 150), hls_thresh=(150, 255)):\n",
    "    \"\"\"\n",
    "    This is is the simple fit which does not used the sliding window approach to find the lane lines\n",
    "    \n",
    "    Args:\n",
    "        img:  The array like image or PIL image\n",
    "        line: The line object which contains the history of the operation\n",
    "        \n",
    "    Returns:\n",
    "        frame_data: The frame data that can be used for the sanity_check or being added to the list of lines\n",
    "    \"\"\"\n",
    "    left_fit = line.current_fit_left\n",
    "    right_fit = line.current_fit_right\n",
    "    binary_image = get_binary_image(img, sobel_thresh, hls_thresh)\n",
    "    binary_warped, M, Minv = transform_bird_eye(binary_image)\n",
    "    margin = 100\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    left_fit_poly, right_fit_poly, left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    left_curverad, right_curverad, dest_from_center =  measure_curvature_real(left_fitx, right_fitx, ploty)\n",
    "    frame_data = FrameData()\n",
    "    frame_data.left_fit = left_fit_poly\n",
    "    frame_data.right_fit = right_fit_poly\n",
    "    frame_data.left_fitx = left_fitx\n",
    "    frame_data.right_fitx = right_fitx\n",
    "    frame_data.ploty = ploty\n",
    "    frame_data.right_curverad = right_curverad\n",
    "    frame_data.left_curverad = left_curverad\n",
    "    frame_data.curvature = sanitize_curvature(left_curverad, right_curverad)\n",
    "    frame_data.dest_from_center = dest_from_center\n",
    "    return frame_data\n",
    "\n",
    "def sanitiy_check(frame_data, line):\n",
    "    \"\"\"\n",
    "    Checks if the given line is a valid line with the sanity check.\n",
    "    \n",
    "    Args:\n",
    "        image: The image that should be used.\n",
    "        line: The line object that should be used for the line\n",
    "        \n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    xm_per_pix = 3.7/700\n",
    "    lane_width = abs(frame_data.left_fitx[-1] - frame_data.right_fitx[-1]) * xm_per_pix\n",
    "    if np.abs(lane_width - 3.7) > MAX_ACCEPTABLE_WIDTH:\n",
    "        return False\n",
    "    curve_differs = np.abs((frame_data.left_curverad - frame_data.right_curverad) / frame_data.left_curverad)\n",
    "    if curve_differs > MAX_ACCEPTABLE_PARALEL:\n",
    "        return False\n",
    "    lane_moved = np.abs(frame_data.dest_from_center - line.line_base_pos)\n",
    "    if lane_moved > MAX_ACCEPTABLE_LINE_MOVED:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def add_line(line, frame_data):\n",
    "    \"\"\"\n",
    "    Adds a new line to the given buffer.\n",
    "    \n",
    "    Args:\n",
    "        line: The empty line object which will be field with the data of the\n",
    "        frame_data: The data that is extracted from the given frame\n",
    "        \n",
    "    Returns:\n",
    "        line: The mainpulate line buffer\n",
    "    \"\"\"\n",
    "    if len(line.recent_xfitted_left) == 0:\n",
    "        ## If the buffer is empty fill it with the first value.\n",
    "        line.detected = True\n",
    "        line.recent_xfitted_left.append(frame_data.left_fitx)\n",
    "        line.recent_xfitted_right.append(frame_data.right_fitx)\n",
    "        line.best_x_left = frame_data.left_fitx\n",
    "        line.best_x_right = frame_data.right_fitx\n",
    "        line.best_fit_left = frame_data.left_fit\n",
    "        line.best_fit_right = frame_data.right_fit\n",
    "        line.recent_fits_left.append(frame_data.left_fit)\n",
    "        line.recent_fits_right.append(frame_data.right_fit)\n",
    "        line.current_fit_left = frame_data.left_fit\n",
    "        line.current_fit_right = frame_data.right_fit\n",
    "        line.radius_of_curvature = frame_data.curvature\n",
    "        line.line_base_pos = frame_data.dest_from_center\n",
    "        line.allx_left = frame_data.left_fitx\n",
    "        line.allx_right = frame_data.right_fitx\n",
    "        line.ally = frame_data.ploty\n",
    "    else:\n",
    "        line.detected = True\n",
    "        line.recent_xfitted_left.append(frame_data.left_fitx)\n",
    "        line.recent_xfitted_right.append(frame_data.right_fitx)\n",
    "        line.best_x_left = np.mean(np.array(line.recent_xfitted_left),axis=0)\n",
    "        line.best_x_right = np.mean(np.array(line.recent_xfitted_right),axis=0)\n",
    "        line.best_fit_left = np.mean(np.array(line.recent_fits_left),axis=0)\n",
    "        line.best_fit_right = np.mean(np.array(line.recent_fits_right),axis=0)\n",
    "        line.recent_fits_left.append(frame_data.left_fit)\n",
    "        line.recent_fits_right.append(frame_data.right_fit)\n",
    "        line.diffs_left = np.absolute(line.current_fit_left - frame_data.left_fit)\n",
    "        line.diffs_right = np.absolute(line.current_fit_right - frame_data.right_fit)\n",
    "        line.current_fit_left = frame_data.left_fit\n",
    "        line.current_fit_right =frame_data.right_fit\n",
    "        line.radius_of_curvature = frame_data.curvature\n",
    "        line.line_base_pos = frame_data.dest_from_center\n",
    "        line.allx_left = frame_data.left_fitx\n",
    "        line.allx_right = frame_data.right_fitx\n",
    "        line.ally = frame_data.ploty\n",
    "    return line\n",
    "\n",
    "def draw_frame(img, frame_data):\n",
    "    \"\"\"\n",
    "    Draws the frame_data retrieved data on the given image.\n",
    "    \n",
    "    Args:\n",
    "        img:        The array like image or image file\n",
    "        frame_data: The frame_data calculated data\n",
    "    \n",
    "    Return:\n",
    "        img\n",
    "    \"\"\"\n",
    "    undist = undistort_image(img)\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    top_down, M, Minv = transform_bird_eye(gray)\n",
    "    warp_zero = np.zeros_like(top_down).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    left_fitx = frame_data.left_fitx\n",
    "    right_fitx = frame_data.right_fitx\n",
    "    ploty = frame_data.ploty\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    curvature_text = \"Curvature:% 6.0fm\" % frame_data.curvature\n",
    "    position_text = \"Position: % 5.2fm\" % frame_data.dest_from_center\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result, curvature_text,(100,70), font, 2,(0,0,0),2)\n",
    "    cv2.putText(result, position_text, (150,120), font, 2,(0,0,0),2)\n",
    "    return result\n",
    "\n",
    "def pipeline(image, **params):\n",
    "    \"\"\"\n",
    "    The pipeline for the image processing\n",
    "    \n",
    "    Args:\n",
    "        image: The array like image or PIL image\n",
    "        params: The parameters that should be used.\n",
    "    \n",
    "    Returns: The finished image.\n",
    "    \"\"\"\n",
    "    line = params[\"line\"]\n",
    "    if len(line.recent_xfitted_left) == 0:\n",
    "        frame_data, M, Minv = brute_force_fit(image)\n",
    "        add_line(line, frame_data)\n",
    "    else:\n",
    "        frame_data = simple_fit(image, line)\n",
    "        if sanitiy_check(frame_data, line):\n",
    "            add_line(line, frame_data)\n",
    "    frame_data = line.get_default_frame_data()\n",
    "    return draw_frame(image, frame_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The buffer the results of the line calculation in the last 10 iteration\n",
    "line = Line()\n",
    "params = {\"line\":line}\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    With this it is possble to pass the parameters to the pipeline.\n",
    "    \n",
    "    Args:\n",
    "        image: The image that should be used, array like image or PIL image\n",
    "    \n",
    "    Return:\n",
    "        The manipulated image\n",
    "    \"\"\"\n",
    "    return pipeline(image, ** params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "output_clip = 'project_view_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "advanced_lane = clip1.fl_image(process_image)\n",
    "%time advanced_lane.write_videofile(output_clip, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
